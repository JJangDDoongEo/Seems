{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab 사용 시 주석 풀고 mount_path 설정 후 실행\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab 사용시 주석 풀고 실행\n",
    "# !pip install transformers\n",
    "# vscode library 설치 안되있을 경우 실행\n",
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab 사용시 주석 풀고 실행\n",
    "# !pip install seaborn\n",
    "# vscode library 설치 안되있을 경우 실행\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab 사용시 주석 풀고 실행\n",
    "# !pip install pytorch-lightning\n",
    "# vscode library 설치 안되있을 경우 실행\n",
    "# %pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lklkk\\anaconda3\\envs\\sejong\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from _init import *\n",
    "\n",
    "from commons import file_util, string_util\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# file_dir variable\n",
    "WORK_DIR = \"../../../\"\n",
    "IN_DIR = WORK_DIR + \"resources/keyword_extract/\"\n",
    "OUT_MODEL_PATH = WORK_DIR + \"resources/keyword_extract_model/bert_model.pt\"\n",
    "DELIM = \"\\t\"\n",
    "TEST_SIZE = 0.112\n",
    "SETP_SIZE = 100\n",
    "\n",
    "# Hyperparameter variable\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 32\n",
    "MAX_SEQ_LEN = 256           # 내가 입력할 문장을 쪼갠 단어의 총 갯수를 의미 -> 자릿수를 맞춰주기 위해 0으로 채우는 것 padding\n",
    "LEARNING_RATE = 2e-5\n",
    "DROPOUT_RATE = 0.3\n",
    "MODE = \"min\"\n",
    "PATIENCE = 3\n",
    "EPOCHS = 50\n",
    "SEED_VAL = 0\n",
    "\n",
    "DENCE_UNIT = 2\n",
    "\n",
    "# 사전학습된 언어 bert model name 활성화\n",
    "# BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "# BERT_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "BERT_MODEL_NAME = \"klue/bert-base\"\n",
    "# 이거는 너무 커서 안돌아감.\n",
    "# BERT_MODEL_NAME = \"klue/roberta-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at : /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU divice name checker\n",
    "if device_name == \"/device:GPU:0\" :\n",
    "    print(\"Found GPU at : {}\".format(device_name))\n",
    "else :\n",
    "    print(\"GPU device not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU :  NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# device setting\n",
    "if torch.cuda.is_available() :\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "    print(\"We will use the GPU : \", torch.cuda.get_device_name(0))\n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using the CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs code 사용 시 데이터 불러오기\n",
    "# data -> list로 넘길 때 사용\n",
    "def load(in_file_path: str, encoding: str, out_list: list) :\n",
    "\tfile_paths = file_util.get_file_paths(in_file_path, True)\n",
    "\n",
    "\tfor file_path in file_paths :\n",
    "\t\tin_file = file_util.open_file(file_path, encoding, \"r\")\n",
    "\n",
    "\t\twhile True :\n",
    "\t\t\tline = in_file.readline()\n",
    "\n",
    "\t\t\tif not line :\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\tline = file_util.preprocess(line)\n",
    "\t\t\tif string_util.is_empty(line, True) :\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tout_list.append(line)\n",
    "\tin_file.close()\n",
    "\n",
    "# 이거 활성화 시켜서 사용하면 됨.\n",
    "# raw_data = []\n",
    "# load(IN_DIR, ENCODING, raw_data)\n",
    "# raw_data = [line.strip().split(DELIM) for line in raw_data]\n",
    "\n",
    "# raw_df = pd.DataFrame(raw_data, columns=[\"train\", \"label\"])\n",
    "# print(raw_df.shape)\n",
    "# raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name 추출\n",
    "file_paths = file_util.get_file_paths(IN_DIR, True)\n",
    "\n",
    "for file_path in file_paths :\n",
    "    file_name = file_util.get_file_name(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12540, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(IN_DIR + file_name, sep=DELIM, names=[\"train\", \"label\"])\n",
    "\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### 이건 테스트 문장입니다 #</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>## 이건 테스트 문장입니다 ##</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># 이건 테스트 문장입니다 ###</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### 엠마누엘 웅가로 / 의상서</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>## 엠마누엘 웅가로 / 의상서 실내</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train  label\n",
       "0    ### 이건 테스트 문장입니다 #      1\n",
       "1    ## 이건 테스트 문장입니다 ##      1\n",
       "2    # 이건 테스트 문장입니다 ###      1\n",
       "3    ### 엠마누엘 웅가로 / 의상서      1\n",
       "4  ## 엠마누엘 웅가로 / 의상서 실내      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기서부터 문맥에 맞게 DATA_RATE 값 변경\n",
      "train - test : 11286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                           train  label\n",
       " 11272     정해 시간을 가지고 찬찬히 보는 것도 한      1\n",
       " 11273  시간을 가지고 찬찬히 보는 것도 한 방법이다.      0\n",
       " 11274    가지고 찬찬히 보는 것도 한 방법이다. #      0\n",
       " 11275       찬찬히 보는 것도 한 방법이다. ##      0\n",
       " 11276          보는 것도 한 방법이다. ###      1,\n",
       "                                     train  label\n",
       " 11277              ### 디자인에 관심이 많은 관람객이라면      1\n",
       " 11278        ## 디자인에 관심이 많은 관람객이라면 이탈리아관을      1\n",
       " 11279     # 디자인에 관심이 많은 관람객이라면 이탈리아관을 반드시      0\n",
       " 11280  디자인에 관심이 많은 관람객이라면 이탈리아관을 반드시 포함해서      1\n",
       " 11281   관심이 많은 관람객이라면 이탈리아관을 반드시 포함해서 스위스      1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_set, test_set 분할\n",
    "# 비율 조정 해서 train 8.1, validation 0.9, test 1.0\n",
    "print(\"여기서부터 문맥에 맞게 DATA_RATE 값 변경\")\n",
    "print(f\"train - test : {int(raw_df.shape[0] * 0.9)}\")\n",
    "DATA_RATE = 11277\n",
    "\n",
    "train_df = raw_df[:DATA_RATE]\n",
    "test_df = raw_df[DATA_RATE:]\n",
    "\n",
    "train_df.tail(), test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              ### 이건 테스트 문장입니다 #\n",
       "1              ## 이건 테스트 문장입니다 ##\n",
       "2              # 이건 테스트 문장입니다 ###\n",
       "3              ### 엠마누엘 웅가로 / 의상서\n",
       "4            ## 엠마누엘 웅가로 / 의상서 실내\n",
       "5      # 엠마누엘 웅가로 / 의상서 실내 장식품으로…\n",
       "6    엠마누엘 웅가로 / 의상서 실내 장식품으로… 디자인\n",
       "7      웅가로 / 의상서 실내 장식품으로… 디자인 세계\n",
       "8       / 의상서 실내 장식품으로… 디자인 세계 넓혀\n",
       "9       의상서 실내 장식품으로… 디자인 세계 넓혀 #\n",
       "Name: train, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = train_df.train\n",
    "sentence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_df.label.values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('### 이건 테스트 문장입니다 #', ['#', '#', '#', '이건', '테스트', '문장', '##입니다', '#'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text tokenizer setting\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentence]\n",
    "\n",
    "sentence[0], tokenized_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    7,     7,     7,  5370,  7453,  6265, 12190,     7,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token embeding\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# sentence를 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_SEQ_LEN, dtype=\"int64\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention masks initializer\n",
    "attention_masks = []\n",
    "\n",
    "for seq in input_ids :\n",
    "    seq_mask = [float(i > 0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "attention_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4297,  2079, 11826,  2069,  4239,  4216,  2205,  2118,  3818,  2088,\n",
      "         1513,  4000,  5793,  2079,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "tensor(1)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([ 3660,  2073,  1570,    17,  5868, 15308,   904,  1063,  1513,  2318,\n",
      "        13395,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# train, validation 분리 -> train : 8, validation : 1, test : 1\n",
    "train_text, val_text, train_label, val_label = train_test_split(\n",
    "    input_ids,\n",
    "    labels,\n",
    "    random_state=0,\n",
    "    test_size=TEST_SIZE\n",
    ")\n",
    "\n",
    "# attention_mask train, validation 분리\n",
    "train_masks, val_masks, _, _ = train_test_split(\n",
    "    attention_masks,\n",
    "    input_ids,\n",
    "    random_state=0,\n",
    "    test_size=TEST_SIZE\n",
    ")\n",
    "\n",
    "# data to pytorch_tensor\n",
    "train_text = torch.tensor(train_text)\n",
    "train_label = torch.tensor(train_label)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "val_text = torch.tensor(val_text)\n",
    "val_label = torch.tensor(val_label)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "\n",
    "print(train_text[0])\n",
    "print(train_label[0])\n",
    "print(train_masks[0])\n",
    "print(val_text[0])\n",
    "print(val_label[0])\n",
    "print(val_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch learning\n",
    "train_data = TensorDataset(train_text, train_masks, train_label)\n",
    "train_sample = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, \n",
    "    sampler=train_sample, \n",
    "    batch_size=TRAIN_BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_data = TensorDataset(val_text, val_masks, val_label)\n",
    "validation_sample = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, \n",
    "    sampler=validation_sample,\n",
    "    batch_size=TRAIN_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11277                  ### 디자인에 관심이 많은 관람객이라면\n",
       "11278            ## 디자인에 관심이 많은 관람객이라면 이탈리아관을\n",
       "11279         # 디자인에 관심이 많은 관람객이라면 이탈리아관을 반드시\n",
       "11280      디자인에 관심이 많은 관람객이라면 이탈리아관을 반드시 포함해서\n",
       "11281       관심이 많은 관람객이라면 이탈리아관을 반드시 포함해서 스위스\n",
       "11282     많은 관람객이라면 이탈리아관을 반드시 포함해서 스위스 프랑스관이\n",
       "11283    관람객이라면 이탈리아관을 반드시 포함해서 스위스 프랑스관이 좋고,\n",
       "11284       이탈리아관을 반드시 포함해서 스위스 프랑스관이 좋고, 관광은\n",
       "11285           반드시 포함해서 스위스 프랑스관이 좋고, 관광은 호주\n",
       "11286          포함해서 스위스 프랑스관이 좋고, 관광은 호주 뉴질랜드\n",
       "Name: train, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_set setting\n",
    "sentence = test_df.train\n",
    "sentence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = test_df.label.values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', '#', '#', '디자인', '##에', '관심', '##이', '많', '##은', '관람객', '##이', '##라면']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentence]\n",
    "\n",
    "# sentence[0]\n",
    "tokenized_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    7,     7,     7,  4482,  2170,  3867,  2052,  1039,  2073,\n",
       "        8369,  2052, 19669,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_texts = pad_sequences(input_texts, maxlen=MAX_SEQ_LEN, dtype=\"int64\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks = []\n",
    "\n",
    "for seq in input_texts :\n",
    "    seq_mask = [float(i > 0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "attention_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    7,     7,     7,  4482,  2170,  3867,  2052,  1039,  2073,  8369,\n",
      "         2052, 19669,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "tensor(1)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "test_texts = torch.tensor(input_texts)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "print(test_texts[0])\n",
    "print(test_labels[0])\n",
    "print(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_texts, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = len(train_df.label.unique())\n",
    "\n",
    "# 각층마다 dropout, dence_unit, activation_function 설정\n",
    "config = BertConfig.from_pretrained(\n",
    "    BERT_MODEL_NAME,                    # 사용할 model name\n",
    "    num_labels=NUM_LABELS,              # label의 갯수\n",
    "    hidden_dropout_prob=DROPOUT_RATE    # Drop 비율\n",
    "    # hidden_act=\"relu\"                   # activation_function\n",
    ")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL_NAME, \n",
    "    config=config\n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lklkk\\anaconda3\\envs\\sejong\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer setting\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = LEARNING_RATE,             # learning_rate\n",
    "    eps = 1e-8                      # 0으로 나누는 것을 방지하기 위한 epsilon_value\n",
    ")\n",
    "\n",
    "# early_stop\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor = \"val_loss\",           # 모니터링할 지표\n",
    "#     mode = MODE,                    # 최대, 최소\n",
    "#     patience = PATIENCE,            # 몇 번 수치가 개선되지 않으면 종료\n",
    "#     verbose = False                # 해당 객체의 로그를 표현 여부\n",
    "# )\n",
    "\n",
    "# train_step : batch count * epochs\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# learning_rate 조절\n",
    "schdeuler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_accuracy function\n",
    "def flat_accuracy(preds, labels) :\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time function\n",
    "def format_time(elapsed) :\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================== Epoch 1 / 50 =========================\n",
      "Training...\n",
      "tensor(0.5187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\tBatch 100 of 626.\t\tElapsed: 0:00:39.\n",
      "tensor(0.5070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\tBatch 200 of 626.\t\tElapsed: 0:01:19.\n",
      "tensor(0.8409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\tBatch 300 of 626.\t\tElapsed: 0:01:58.\n",
      "tensor(0.5694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\tBatch 400 of 626.\t\tElapsed: 0:02:36.\n",
      "tensor(0.4953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\tBatch 500 of 626.\t\tElapsed: 0:03:13.\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\tBatch 600 of 626.\t\tElapsed: 0:03:51.\n",
      "tensor(0.5752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "\n",
      "\tAverage training loss : 0.51\n",
      "\tTraining epcoh took : 0:04:01\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "random.seed(SEED_VAL)\n",
    "np.random.seed(SEED_VAL)\n",
    "torch.manual_seed(SEED_VAL)\n",
    "torch.cuda.manual_seed_all(SEED_VAL)\n",
    "\n",
    "# gradant initializer\n",
    "model.zero_grad()\n",
    "best_loss = float(\"inf\")\n",
    "counter = 0\n",
    "\n",
    "# 모델 학습 및 검증 시작\n",
    "for epoch_i in range(EPOCHS) :\n",
    "    '''\n",
    "        Train\n",
    "    '''\n",
    "    print(\"\")\n",
    "    print(\"======================== Epoch {:} / {:} =========================\".format(epoch_i + 1, EPOCHS))\n",
    "    print(\"Training...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # loss initializer\n",
    "    total_loss = 0\n",
    "\n",
    "    # train mode change\n",
    "    model.train()\n",
    "\n",
    "    # dataloader from batch get data\n",
    "    for step, batch in enumerate(train_dataloader) :\n",
    "        if step % SETP_SIZE == 0 and not step == 0 :\n",
    "            elapsed = format_time(time.time() - start)\n",
    "            \n",
    "            print(\"\\tBatch {:} of {:}.\\t\\tElapsed: {:}.\".format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # GPU in batch\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # batch to data\n",
    "        b_input_texts, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행\n",
    "        outputs = model(\n",
    "            b_input_texts,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "\n",
    "        # loss calculator\n",
    "        loss = outputs[0]\n",
    "        print(loss)\n",
    "\n",
    "        # total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # BackWard\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # weigth update\n",
    "        optimizer.step()\n",
    "\n",
    "        # schduler update\n",
    "        schdeuler.step()\n",
    "\n",
    "        # gradent initalizer\n",
    "        model.zero_grad()\n",
    "\n",
    "    # avg loss\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\\tAverage training loss : {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"\\tTraining epcoh took : {:}\".format(format_time(time.time() - start)))\n",
    "\n",
    "    break\n",
    "\n",
    "    '''\n",
    "        Validation\n",
    "    '''\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # model 평가\n",
    "    model.eval()\n",
    "\n",
    "    # value initalizer\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in validation_dataloader :\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        b_input_texts, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad() :\n",
    "            outputs = model(\n",
    "                b_input_texts,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "            )\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "        # output logits vs label accuracy\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"\\tAccuracy : {0:.2f}\".format(eval_accuracy / nb_eval_steps))\n",
    "    print(\"\\tValidation took : {:}\".format(format_time(time.time() - start)))\n",
    "\n",
    "    # early stop\n",
    "    if avg_train_loss < best_loss :\n",
    "        best_loss = avg_train_loss\n",
    "        counter = 0\n",
    "        print(best_loss)\n",
    "    else :\n",
    "        counter += 1\n",
    "\n",
    "        if counter >= PATIENCE :\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set evalation\n",
    "start = time.time()\n",
    "\n",
    "# eval mode\n",
    "model.eval()\n",
    "\n",
    "# variable initalizer\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# test dataloader batch_size loop\n",
    "for step, batch in enumerate(test_dataloader) :\n",
    "    if step % SETP_SIZE == 0 and not step == 0 :\n",
    "        elapsed = format_time(time.time() - start)\n",
    "        \n",
    "        print(\"\\tBatch {:} of {:}.\\tElapsed : {:}.\".format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    b_input_texts, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        outputs = model(\n",
    "            b_input_texts,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask\n",
    "        )\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy : {0:.2f}\".format(eval_accuracy / nb_eval_steps))\n",
    "print(\"Test took : {:}\".format(format_time(time.time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 저장\n",
    "torch.save(model.state_dict(), OUT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 모델 불러오는 클래스\n",
    "class KeywordExtractorModel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(KeywordExtractorModel, self).__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data convert\n",
    "def convert_input_data(sentence) :\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentence]\n",
    "\n",
    "    # token embeding\n",
    "    input_texts = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "    input_texts = pad_sequences(\n",
    "        input_texts,\n",
    "        maxlen=MAX_SEQ_LEN, \n",
    "        dtype=\"int64\", \n",
    "        truncating=\"post\", \n",
    "        padding=\"post\"\n",
    "    )\n",
    "    attention_masks = []\n",
    "\n",
    "    for seq in input_texts :\n",
    "        seq_mask = [float(i > 0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    \n",
    "    inputs = torch.tensor(input_texts)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence teset\n",
    "def test_sentence(sentence) :\n",
    "    model.eval()\n",
    "\n",
    "    inputs, masks = convert_input_data(sentence)\n",
    "\n",
    "    b_input_texts = inputs.to(device)\n",
    "    b_input_masks = masks.to(device)\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        outputs = model(\n",
    "            b_input_texts,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_masks\n",
    "        )\n",
    "    \n",
    "    logits = outputs[0]\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sentence 생성\n",
    "logits = test_sentence([\"연기는 별로지만 재미 하나는 끝내줌!\"])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 model 불러오기 + 위의 문장 테스트 함수 이용해서 적용되는지 확인 가능.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = KeywordExtractorModel().to(device)\n",
    "\n",
    "# model_state_dict = torch.load(out_dir, map_location=device)\n",
    "# model.load_state_dict(model_state_dict)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sejong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
